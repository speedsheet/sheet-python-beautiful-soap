# <#>Beautiful Soup<> SpeedSheet
<b>Find what you need, faster.<>

<*>Use <b>Search<> to Find Answers Fast (above)
Answers Get Right To The Point
Covers The <b>Beautiful Soup HTML Parsing Library<> for Python<>



# Online Links


### Beautiful Soup Documents
<l>https://www.crummy.com/software/BeautifulSoup/<>

<l>https://beautiful-soup-4.readthedocs.io/en/latest/<>


### Beautiful Soup Library on PyPi
<l>https://pypi.org/project/beautifulsoup4/<>



# Library


## Install Library - pip

<cb>pip install beautifulsoup4<>
@
@ command, commandline



## Install Library - pip requirements.txt

requirements.txt:

<cb>beautifulsoup4<>

Command:

<cb>pip install -r requiremets.txt<>
@
@ command, commandline



## Program - Import

<cb>from bs4 import BeautifulSoup<>



# Hello World


### Read Google

<cb>from urllib.request import urlopen
from bs4 import BeautifulSoup

with urlopen('<v>https://google.com<>') as <v>response<>:
	<v>content<> = <v>response<>.read()

<v>soup<> = BeautifulSoup(<v>content<>, 'html.parser')

print(<v>soup<>.title)<>



# Parse


### Parse HTML - Using Python's Stock Parser

<cb>= BeautifulSoup(<v>content<>, 'html.parser')<>

Usage:

<cb>from bs4 import BeautifulSoup

<v>soup<> = BeautifulSoup(<v>content<>, 'html.parser')<>
@
@ html.parser
@ bs.BeautifulSoup(), BeautifulSoup()



### Parse HTML - Using lxml

<cb>= BeautifulSoup(<v>content<>, 'lxml')<>

Usage:

<cb>from bs4 import BeautifulSoup

<v>soup<> = BeautifulSoup(<v>content<>, 'lxml')<>

Requires lxml:

pip / requirements.txt

<cb>lxml<>
@
@ bs.BeautifulSoup(), BeautifulSoup()



### Parse XML - Using lxml

<cb>= BeautifulSoup(<v>content<>, 'xml')<>

Usage:

<cb>from bs4 import BeautifulSoup

<v>soup<> = BeautifulSoup(<v>content<>, 'xml')<>

Requires lxml:

pip / requirements.txt

<cb>lxml<>
@
@ xml
@ bs.BeautifulSoup(), BeautifulSoup()



# Page


### Page - Body

<cb>= <v>soup<>.body<>


Returns the body element of the page.
@
@ .body



### Page - Head

<cb>= <v>soup<>.head<>


Returns the head element of the page.
@
@ .head



### Page - HTML

<cb>= str(<v>soup<>)<>


Returns the page HTML.


### Page - Links

<cb>= [ <v>element<>['href']
        for <v>element<> in <v>soup<>.find_all('a') if 'href' in <v>element<>.attrs]<>


Returns all page links.


### Page - Title

<cb>= <v>soup<>.title.string<>


### Page - Text - Entire Text

<cb>= <v>soup<>.get_text()<>


### Page - Find By Element Type

<cb>= <v>soup<>.find(<v>element_type<>)<>
@
@ .find()


### Page - Find By Class Name

<cb>= <v>soup<>.find(_class = <v>class_name<>)<>
@
@ .find()


### Page - Find By ID

<cb>= <v>soup<>.find(id = <v>id<>)<>
@
@ .find()


### Page - Find All

<cb>= <v>soup<>.find_all()<>


Returns all sub-elements.
@
@ .find_all()


### Page - Find All By Element Type

<cb>= <v>soup<>.find_all(<v>element_type<>)<>
@
@ .find_all()


### Page - Find All By Class Name

<cb>= <v>soup<>.find_all(_class = <v>class_name<>)<>
@
@ .find_all()



# Element


### Element - Get Name

<cb>= <v>element<>.name<>


Returns the name of the element.
@
@ .name


### Element - Get Text

<cb>= <v>element<>.string<>


Returns the inner text of the element.
@
@ .string, .get_text()



### Element - Get HTML

<cb>= str(<v>element<>)<>



### Element - Get Children

<cb>= <v>element<>.children<>
@
@ .children


### Element - Get Parent

<cb>= <v>element<>.parent<>


Returns the parent element of the element.
@
@ .parent


### Element - Get Attribute

<cb>= <v>element<>['<v>attribute<>']<>

or

<cb>= <v>element<>.get('<v>attribute<>')<>
@
@ [], .get()


### Element - Get Attributes

<cb>= <v>element<>.attrs<>

(dict of attribute name, values?)
@
@ .attrs, attrs


### Element - Attribute - Contains?

<cb>if '<v>attribute<>' in <v>element<>.attrs:<>
@
@ has, exists, if in
@ .attrs


### Element - Get Class

<cb>= <v>element<>['class']<>
@
@ [], .get()


### Element - Get ID

<cb>= <v>element<>['id']<>
@
@ [], .get()


### Element - Find By Element Type

<cb>= <v>element<>.find(<v>element_type<>)<>
@
@ .find()


### Element - Find By Class Name

<cb>= <v>element<>.find(_class = <v>class_name<>)<>
@
@ .find()


### Element - Find By ID

<cb>= <v>element<>.find(id = <v>id<>)<>
@
@ .find()


### Element - Find All

<cb>= <v>element<>.find_all()<>


Returns all sub-elements.
@
@ .find_all()


### Element - Find All By Element Type

<cb>= <v>element<>.find_all(<v>element_type<>)<>
@
@ .find_all()


### Element - Find All By Class Name

<cb>= <v>element<>.find_all(_class = <v>class_name<>)<>
@
@ .find_all()


# Terms


### lxml
A fast library for parsing XML and HTML.

Wraps the C librarie libxml2 and libxslt.

Home Page:
<l>https://lxml.de/<>

PyPi:
<l>https://pypi.org/project/lxml/<>



### XPath

Not supported by BeautifulSoap